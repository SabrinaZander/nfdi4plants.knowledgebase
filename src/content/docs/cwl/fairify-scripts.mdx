---
title: From Script to CWL
lastUpdated: 2025-07-09
authors:
  - dominik-brilhaus
---

import { FileTree } from '@astrojs/starlight/components';
import { Steps } from '@astrojs/starlight/components';
import { Tabs, TabItem } from '@astrojs/starlight/components';
import Mermaid from '@components/mdx/Mermaid.astro'


This starterâ€™s guide to **FAIRifying script-based data analysis workflows** walks you through the steps to turn your existing script into a **reusable CWL workflow**. Whether you use Bash, Python, R, or another language the same logic applies.

## Recommendations for FAIR data analysis

These recommendations are good coding practice independently of the steps below.

<Steps>

1. Follow the [KISS principle](https://en.wikipedia.org/wiki/KISS_principle) and **Keep It Single-Step**
    - A script should ideally only execute a single process
    - Modular, easier to combine in multi-step pipelines
    - More reusable
    - Easier to follow and annotate what the script consumes (`inputs`) and creates (`outputs`)
2. **Do not hard code input or output paths**
    - Reusability
3. Collect information about external packages and tools the script depends on
    - Packages
    - Record the version
    - Record online resources (URLs, biotool ro SciCrunch IDs, GitHub site)

</Steps>

---

## Identify Inputs and Outputs

Look through your script and **identify what data it reads and what data it writes**. These are your `inputs` and `outputs`.

### Examples

- Input: a CSV file, a FASTA file.
- Output: a figure, a table, a processed file.

### Goal

Make a list like:

```yaml
inputs:
  - input_data: "data.csv"

outputs:
  - result_file: "results/summary.csv"
```

---

## Refactor the script

**Replace hard-coded paths** (pointing to your `inputs` and `outputs`) with command-line arguments. For easier handling, move these input/output variables to its own section (e.g. on top of your script).

### Example

Each script below reads a CSV file (`data.csv`), sorts it by the first column, and writes the result to `sorted.csv`.


Change this...

<Tabs syncKey="pl">

<TabItem label="Python" icon='seti:python'>

```python 
import sys
import pandas as pd

data = pd.read_csv("data.csv")
data_sorted = data.sort_values(by=data.columns[0])
data_sorted.to_csv("sorted.csv", index=False)
```

</TabItem>

<TabItem label="R" icon='seti:R'>

```r 
data <- read.csv("data.csv")
data_sorted <- data[order(data[[1]]), ]
write.csv(data_sorted, "sorted.csv", row.names=FALSE)
```

</TabItem>


<TabItem label="Bash" icon='seti:shell'>

```bash 
#!/bin/bash

(head -n 1 data.csv && tail -n +2 data.csv | sort) > sorted.csv
```

</TabItem>

</Tabs>

...to this:

<Tabs syncKey="pl">

<TabItem label="Python" icon='seti:python'>

```python title="sort-csv.py"
import sys
import pandas as pd

input_file = sys.argv[1]
output_file = sys.argv[2]

data = pd.read_csv(input_file)
data_sorted = data.sort_values(by=data.columns[0])
data_sorted.to_csv(output_file, index=False)
```

</TabItem>

<TabItem label="R" icon='seti:R'>

```r title="sort-csv.R"
args <- commandArgs(trailingOnly=TRUE)
input_file <- args[1]
output_file <- args[2]

data <- read.csv(input_file)
data_sorted <- data[order(data[[1]]), ]
write.csv(data_sorted, output_file, row.names=FALSE)
```

</TabItem>

<TabItem label="Bash" icon='seti:shell'>

```bash title="sort-csv.sh"
#!/bin/bash
input_file="$1"
output_file="$2"

(head -n 1 "$input_file" && tail -n +2 "$input_file" | sort) > "$output_file"
```

</TabItem>

</Tabs>


The script can then be run via

<Tabs syncKey="pl">

<TabItem label="Python" icon='seti:python'>

```bash
python sort-csv.py data.csv sorted.csv
```

</TabItem>

<TabItem label="R" icon='seti:R'>

```bash
Rscript sort-csv.R data.csv sorted.csv
```

</TabItem>

<TabItem label="Bash" icon='seti:shell'>

```bash
bash sort-csv.sh data.csv sorted.csv
```

</TabItem>

</Tabs>



### Goal

This makes your script **modular and reusable**.

---

## Write a minimal Workflow CWL File

Create a file named `workflow.cwl`.

### Example

<Tabs syncKey="pl">

<TabItem label="Python" icon='seti:python'>

```yaml title="workflow.cwl"
cwlVersion: v1.2
class: CommandLineTool
requirements:
  - class: InitialWorkDirRequirement
    listing:
      - entryname: sort-csv.py
        entry:
          $include: sort-csv.py
baseCommand: [python3, sort-csv.py]
inputs:
  input_file:
    type: File
    inputBinding:
      position: 1
  output_filename:
    type: string
outputs:
  output_file:
    type: File
    outputBinding:
      glob: $(inputs.output_filename)
```

</TabItem>

<TabItem label="R" icon='seti:R'>

```yaml title="workflow.cwl"
cwlVersion: v1.2
class: CommandLineTool
requirements:
  - class: InitialWorkDirRequirement
    listing:
      - entryname: sort-csv.R
        entry:
          $include: sort-csv.R
baseCommand: [Rscript, sort-csv.R]
inputs:
  input_file:
    type: File
    inputBinding:
      position: 1
  output_filename:
    type: string
outputs:
  output_file:
    type: File
    outputBinding:
      glob: $(inputs.output_filename)
```

</TabItem>

<TabItem label="Bash" icon='seti:shell'>

```yaml title="workflow.cwl"
cwlVersion: v1.2
class: CommandLineTool
requirements:
  - class: InitialWorkDirRequirement
    listing:
      - entryname: sort-csv.sh
        entry:
          $include: sort-csv.sh
baseCommand: [bash, sort-csv.sh]
inputs:
  input_file:
    type: File
    inputBinding:
      position: 1
  output_filename:
    type: string
outputs:
  output_file:
    type: File
    outputBinding:
      glob: $(inputs.output_filename)
```


</TabItem>

</Tabs>


### Goal 

This wraps your script in CWL as a `CommandLineTool` and basically runs e.g. `python3 sort-csv.py data.csv sorted.csv`.

:::note
Make sure your script (`sort-csv.py`) is saved alongside `workflow.cwl`.
:::

---

## Add a minimal `Run`

Create a `run.cwl` file that uses your `workflow.cwl`.

### Example

```yaml titles="run.cwl"
cwlVersion: v1.2
class: Workflow

inputs:
  input_file: File
  output_filename: string

steps:
  step1:
    run: workflow.cwl
    in:
      input_file: input_file
      output_filename: output_filename
    out: [output_file]

outputs:
  output_file:
    type: File
    outputSource: step1/output_file
```

Also create a suitable `run.yml` to provide the parameters required by the `run.cwl`:

```yaml title="run.yml"
input_file: data.csv
output_filename: sorted.csv
```

### Goal


Then run it with:

```bash
cwltool run.cwl run.yml
```

---

## Identify Required Tools and Packages

Go back to your script and **list all external packages and tools it depends on**.

### Example

Look for e.g.

- Python packages (`pandas`, `numpy`)
- R libraries (`ggplot2`)
- Command-line tools (`samtools`, `awk`)

### Goal

---

## Collect Metadata About Dependencies

Record:

- **Exact package names**
- **Versions**

### Example

- pandas, version 1.5.3
- numpy, version 1.23.0

This helps others reproduce your analysis precisely.

## Add dependencies to `hints` and `requirements`

In `workflow.cwl`, add a `SoftwareRequirement`

### Soft requirements = `hints`

Specify software and resource requirements under `hints`

- add `SoftwareRequirement` to specify software version and reference
  - `package: ` name of the software or package
  - `specs: ` reference url from https://identifiers.org/biotools/ or SciCrunch https://identifiers.org/rrid/
  - `version: [ "0.11.9" ]`

- add `ResourceRequirement` to specify the required compute resources

### Example

```yaml
hints:
  - class: SoftwareRequirement
    packages:
      - package: python
        version: [3.10]
      - package: pandas
        version: [1.5.3]
```

### Hard requirements = `requirements`

Use the `requirements` primarily to specify hard requirements needed to run the current `CommandLineTool` or `Workflow` document

---

## Add a Docker Container

For full portability, specify a container with all dependencies.
Use the `DockerRequirement` to load a published Docker image or reference a local `Dockerfile`.

### Example

Load a public image

```yaml title="workflow.cwl"
requirements:
  - class: DockerRequirement
    dockerPull: python:3.10-slim
```

Create your own `Dockerfile` ...

```Dockerfile title="Dockerfile"
FROM python:3.10-slim
RUN pip install pandas==1.5.3 numpy==1.23.0
```

...and load it in your `workflow.cwl`

```yaml title="workflow.cwl"

...
hints:
  DockerRequirement:
    dockerImageId: "mydocker"
    dockerFile: {$include: "Dockerfile"}
...

```



## Metadata

### Namespaces and schemas

Adding namespaces and schemas allows to reuse them elsewhere in a CWL document

```yaml
$namespaces:
  s: https://schema.org/
  edam: http://edamontology.org/

$schemas:
  - https://schema.org/version/latest/schemaorg-current-https.rdf
  - http://edamontology.org/EDAM_1.18.owl
```

### Attribute authors and contributors

```yaml
s:author:
  - class: s:Person
    s:identifier: <author ORCID>
    s:email: mailto:<author email>
    s:name: <author name>

s:contributor:
  - class: s:Person
    s:identifier: <contributor ORCID>
    s:email: mailto:<contributor email>
    s:name: <contributor name>

```


## Resources

This guide is adapted and includes recommendations from:

- https://www.commonwl.org/user_guide/topics/best-practices.html
- https://www.commonwl.org/user_guide/topics/metadata-and-authorship.html 